{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de6cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f223827",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.finalvenv (3.12.11) (Python 3.12.11)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Rayan Ahmed.R/Downloads/Agentic/.finalvenv/bin/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import  ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6975c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv,description=\"Query arxiv papers\")\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5a5966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2021-05-06\\nTitle: Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet\\nAuthors: Luke Melas-Kyriazi\\nSummary: The strong performance of vision transformers on image classification and other vision tasks is often attributed to the design of their multi-head attention layers. However, the extent to which attention is responsible for this strong performance remains unclear. In this short report, we ask: is the attention layer even necessary? Specifi'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c9de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=500)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "print(wiki.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b3bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13c56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee2ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "API_KEY=os.getenv(\"API_KEY\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"tvapikey\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c9e56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8e3592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.artificialintelligence-news.com/',\n",
       "  'content': '### Zara’s use of AI shows how retail workflows are quietly changing\\n\\nDeep Dives\\n\\nDecember 19, 2025\\n\\n### Roblox brings AI into the Studio to speed up game creation\\n\\nAI in Action\\n\\nDecember 17, 2025\\n\\n#### Industries\\n\\n### Disney is embedding generative AI into its operating model\\n\\nEntertainment & Media\\n\\nDecember 24, 2025\\n\\n### Arm and the future of AI at the edge\\n\\nAI Hardware & Chips\\n\\nDecember 23, 2025\\n\\n### Marketing agencies using AI in workflows serve more clients\\n\\nMarketing AI [...] October 30, 2025\\n\\n### Malaysia launches Ryt Bank, its first AI-powered bank\\n\\nFinance AI\\n\\nAugust 26, 2025\\n\\n### Google’s Veo 3 AI video creation tools are now widely available\\n\\nAI in Action\\n\\nJuly 29, 2025\\n\\n#### Computer Vision\\n\\n### US and Japan announce sweeping AI and tech collaboration\\n\\nArtificial Intelligence\\n\\nApril 11, 2024\\n\\n### UK and Canada sign AI compute agreement\\n\\nArtificial Intelligence\\n\\nJanuary 31, 2024\\n\\n### Quantum AI represents a ‘transformative advancement’\\n\\nAI Hardware & Chips [...] November 14, 2023\\n\\n#### Machine Learning\\n\\n### How AI is changing the way we travel\\n\\nArtificial Intelligence\\n\\nOctober 7, 2025\\n\\n### Spot AI introduces the world’s first universal AI agent builder for security cameras\\n\\nArtificial Intelligence\\n\\nApril 10, 2025\\n\\n### Tony Blair Institute AI copyright report sparks backlash\\n\\nArtificial Intelligence\\n\\nApril 2, 2025\\n\\n#### Enterprise\\n\\n### Disney is embedding generative AI into its operating model\\n\\nEntertainment & Media\\n\\nDecember 24, 2025'},\n",
       " {'url': 'https://news.microsoft.com/source/features/ai/whats-next-in-ai-7-trends-to-watch-in-2026/',\n",
       "  'content': 'Aparna Chennapragada, Microsoft’s chief product officer for AI experiences, sees 2026 as a new era for alliances between technology and people. If recent years were about AI answering questions and reasoning through problems, the next wave will be about true collaboration, Chennapragada says.\\n\\n“The future isn’t about replacing humans,” she says. “It’s about amplifying them.” [...] “Quantum advantage will drive breakthroughs in materials, medicine and more,” Zander says. “The future of AI and science won’t just be faster, it will be fundamentally redefined.”\\n\\nLead image created by Kathy Oneha / We. Communications. Illustrations produced with Create in Microsoft 365 Copilot. Story published on Dec. 8, 2025.\\n\\n## Learn more about the latest technology and trends\\n\\n### What’s next in AI? Field notes from Microsoft Research for 2026 [...] This transformation is visible everywhere. In medicine, AI is helping close gaps in care. In software development, it’s learning not just code but the context behind it. In scientific research, it’s becoming a true lab assistant. In quantum computing, new hybrid approaches are heralding breakthroughs once thought impossible.'},\n",
       " {'url': 'https://www.ibm.com/think/news/ai-tech-trends-predictions-2026',\n",
       "  'content': 'A year ago, Matt White, Executive Director of the PyTorch Foundation, predicted that smaller models will push AI to the edge.\\n\\n“The industry validated the thesis that smaller, domain-optimized models would become central,” White recently told IBM Think. “Advances in distillation, quantization and memory-efficient runtimes pushed inference to edge clusters and embedded devices, driven by cost, latency and data-sovereignty needs.” [...] ### The latest AI trends, brought to you by experts\\n\\nGet curated insights on the most important—and intriguing—AI news. Subscribe to our weekly Think newsletter. See the IBM Privacy Statement.\\n\\n### Thank you! You are subscribed.\\n\\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information. [...] “We’ve moved past the era of single-purpose agents,” Chris Hay, Distinguished Engineer at IBM, said during a recent Mixture of Experts episode. In 2024, agents were small and specialized: the email writer, the research helper. But now, with reasoning capabilities, agents can plan, call tools and complete complex tasks.\\n\\n“We’re seeing the rise of what I call the ‘super agent,’” Hay said.'},\n",
       " {'url': 'https://news.mit.edu/topic/artificial-intelligence2',\n",
       "  'content': 'December 18, 2025\\n\\nRead full story →\\n\\n6 cartoon illustrations of cats in various interactions with a cardboard box.\\n\\n### A new way to increase the capabilities of large language models\\n\\nMIT-IBM Watson AI Lab researchers developed an expressive architecture that provides better state tracking and sequential reasoning in LLMs over long texts.\\n\\nDecember 17, 2025\\n\\nRead full story →\\n\\nAn eye made of zeroes and ones.\\n\\n### A “scientific sandbox” lets researchers explore the evolution of vision systems'},\n",
       " {'url': 'https://techcrunch.com/category/artificial-intelligence/',\n",
       "  'content': '### Meta just bought Manus, an AI startup everyone has been talking about\\n\\n### 2025 was the year AI got a vibe check\\n\\n### Plaud Note Pro is an excellent AI-powered recorder that I carry everywhere\\n\\nChatGPT logo\\n\\n### How to use the new ChatGPT app integrations, including DoorDash, Spotify, Uber, and others\\n\\nenterprise, 2024, predictions, venture capital, startups\\n\\n### VCs predict strong enterprise AI adoption next year — again [...] ### Topics\\n\\nLatest\\n\\nAI\\n\\nAmazon\\n\\nApps\\n\\nBiotech & Health\\n\\nClimate\\n\\nCloud Computing\\n\\nCommerce\\n\\nCrypto\\n\\nEnterprise\\n\\nEVs\\n\\nFintech\\n\\nFundraising\\n\\nGadgets\\n\\nGaming\\n\\nGoogle\\n\\nGovernment & Policy\\n\\nHardware\\n\\nInstagram\\n\\nLayoffs\\n\\nMedia & Entertainment\\n\\nMeta\\n\\nMicrosoft\\n\\nPrivacy\\n\\nRobotics\\n\\nSecurity\\n\\nSocial\\n\\nSpace\\n\\nStartups\\n\\nTikTok\\n\\nTransportation\\n\\nVenture\\n\\n### More from TechCrunch\\n\\nStaff\\n\\nEvents\\n\\nStartup Battlefield\\n\\nStrictlyVC\\n\\nNewsletters\\n\\nPodcasts\\n\\nVideos\\n\\nPartner Content\\n\\nTechCrunch Brand Studio\\n\\nCrunchboard [...] Contact Us\\n\\n# AI\\n\\nNews coverage on artificial intelligence and machine learning tech, the companies building them, and the ethical issues AI raises today. This encompasses generative AI, including large language models, text-to-image and text-to-video models; speech recognition and generation; and predictive analytics.\\n\\n### \\n\\nThe Grok logo appears on a phone and the xAI logo is displayed on a laptop.\\n\\n### India orders Musk’s X to fix Grok over ‘obscene’ AI content'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"Provide me the recent AI new?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f7588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[arxiv,wiki,tavily]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b56e0a21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ModelProfileRegistry' from 'langchain_core.language_models' (c:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_core\\language_models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      2\u001b[0m llm\u001b[38;5;241m=\u001b[39mChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://openrouter.ai/api/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,api_key\u001b[38;5;241m=\u001b[39mAPI_KEY,max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_openai\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Module for OpenAI integrations.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "File \u001b[1;32mc:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Module for OpenAI chat models.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\azure.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, SecretStr, model_validator\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Self\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseChatOpenAI, _get_default_model_profile\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m _BM \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_BM\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mBaseModel)\n",
      "File \u001b[1;32mc:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:43\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     AsyncCallbackManagerForLLMRun,\n\u001b[0;32m     41\u001b[0m     CallbackManagerForLLMRun,\n\u001b[0;32m     42\u001b[0m )\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     44\u001b[0m     LanguageModelInput,\n\u001b[0;32m     45\u001b[0m     ModelProfileRegistry,\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     48\u001b[0m     BaseChatModel,\n\u001b[0;32m     49\u001b[0m     LangSmithParams,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     52\u001b[0m     AIMessage,\n\u001b[0;32m     53\u001b[0m     AIMessageChunk,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     is_data_content_block,\n\u001b[0;32m     69\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ModelProfileRegistry' from 'langchain_core.language_models' (c:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_core\\language_models\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4.1\",base_url=\"https://openrouter.ai/api/v1\",api_key=API_KEY,max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8f0cd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ModelProfile' from 'langchain_core.language_models' (c:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_core\\language_models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_groq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize Groq chat model using the API key\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_groq\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Groq integration for LangChain.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_groq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_groq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGroq\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_groq\\chat_models.py:15\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Literal, cast\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     AsyncCallbackManagerForLLMRun,\n\u001b[0;32m     13\u001b[0m     CallbackManagerForLLMRun,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     LanguageModelInput,\n\u001b[0;32m     17\u001b[0m     ModelProfile,\n\u001b[0;32m     18\u001b[0m     ModelProfileRegistry,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     BaseChatModel,\n\u001b[0;32m     22\u001b[0m     LangSmithParams,\n\u001b[0;32m     23\u001b[0m     agenerate_from_stream,\n\u001b[0;32m     24\u001b[0m     generate_from_stream,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     AIMessage,\n\u001b[0;32m     28\u001b[0m     AIMessageChunk,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     ToolMessageChunk,\n\u001b[0;32m     43\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ModelProfile' from 'langchain_core.language_models' (c:\\Users\\Rayan Ahmed.R\\Downloads\\Agentic\\.venv\\lib\\site-packages\\langchain_core\\language_models\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "# Initialize Groq chat model using the API key\n",
    "groq_api_key=os.getenv(\"groqkey\")\n",
    "chat = GroqChat(api_key=groq_api_key)\n",
    "\n",
    "# Example usage\n",
    "response = chat.predict(\"Hello, how are you?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ceaa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**AI** stands for **Artificial Intelligence**. It refers to the ability of machines or computer programs to perform tasks that typically require human intelligence. This includes learning, reasoning, problem-solving, perception, understanding language, recognizing patterns, and sometimes even creativity.\\n\\n### Key Points:\\n- **Artificial**: Made by humans, not natural.\\n- **Intelligence**: Ability to think, learn, and make decisions.\\n\\n### Common Types of AI:\\n- **Narrow AI (Weak AI):** Does specific tasks (e.g., voice assistants like Siri, chatbots).\\n- **General AI (Strong AI):** Would do any intellectual task that a human can (this does not yet exist).\\n\\n### Examples of AI in Everyday Life:\\n- Virtual assistants (Alexa, Siri, Google Assistant)\\n- Recommendation systems (Netflix, YouTube)\\n- Self-driving cars\\n- Face recognition in smartphones\\n- Chatbots (like me!)\\n\\n### How Does AI Work?\\nAI often uses:\\n- **Data:** Lots of information to learn from\\n- **Algorithms:** Step-by-step instructions the computer follows\\n- **Machine Learning & Deep Learning:** Ways for computers to “learn” from data and improve over time\\n\\n### In Short:\\n**AI is the science and engineering of making computers and machines behave in ways that we would call intelligent if a human were doing them.**', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 273, 'prompt_tokens': 11, 'total_tokens': 284, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 0.002206, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 2.2e-05, 'upstream_inference_completions_cost': 0.002184}}, 'model_name': 'openai/gpt-4.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-62a98909-26c7-4c32-9a3a-9796e993b1ae-0', usage_metadata={'input_tokens': 11, 'output_tokens': 273, 'total_tokens': 284})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63067139",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223b7fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8jGIbR0JzJGFmTh0LLTCNgjI', 'function': {'arguments': '{\"query\":\"recent news on AI\"}', 'name': 'tavily_search_results_json'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 165, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 0.000506, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0.00033, 'upstream_inference_completions_cost': 0.000176}}, 'model_name': 'openai/gpt-4.1', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7b1db064-4287-4567-965f-e364a8253487-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'recent news on AI'}, 'id': 'call_8jGIbR0JzJGFmTh0LLTCNgjI', 'type': 'tool_call'}], usage_metadata={'input_tokens': 165, 'output_tokens': 22, 'total_tokens': 187})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"What is the recent news on AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b5e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uM7CZa3gfVTRphZUCJXBKVUL', 'function': {'arguments': '{\"query\":\"quantum computing\"}', 'name': 'arxiv'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 166, 'total_tokens': 183, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 0.000468, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0.000332, 'upstream_inference_completions_cost': 0.000136}}, 'model_name': 'openai/gpt-4.1', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-307f63c0-034e-40ff-8fda-e85a0eee0708-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'quantum computing'}, 'id': 'call_uM7CZa3gfVTRphZUCJXBKVUL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 166, 'output_tokens': 17, 'total_tokens': 183})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"What is the latest research on quantum computing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d198c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Machine learning** is a branch of artificial intelligence (AI) that focuses on developing algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data, without being explicitly programmed for each specific task.\\n\\n### Key Points:\\n- **Learning from Data:** Machine learning systems improve their performance as they are exposed to more data.\\n- **Types of Machine Learning:**\\n  - **Supervised Learning:** The algorithm is trained on labeled data (data with correct answers).\\n  - **Unsupervised Learning:** The algorithm finds patterns or structures in data that is not labeled.\\n  - **Reinforcement Learning:** The algorithm learns by receiving feedback based on its actions (rewards or punishments).\\n- **Applications:** Machine learning is used in a wide range of fields, including speech recognition, image analysis, self-driving cars, medical diagnosis, and more.\\n\\n**In short**, machine learning enables computers to automatically learn and improve from experience, adapting to new data without human intervention.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 162, 'total_tokens': 363, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 0.001932, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0.000324, 'upstream_inference_completions_cost': 0.001608}}, 'model_name': 'openai/gpt-4.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5e4421d1-f6b5-41ac-9982-42402a9a7e33-0', usage_metadata={'input_tokens': 162, 'output_tokens': 201, 'total_tokens': 363})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"what is machine learning?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ab5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e74e8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage],add_messages]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "215565d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image,display\n",
    "from langgraph.graph import StateGraph , START , END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9d04408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## edges\n",
    "builder.add_edge(START,\"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "graph=builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff53419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "1706.03762\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_dly1ogFBQJR1UrP44DvuZj9o)\n",
      " Call ID: call_dly1ogFBQJR1UrP44DvuZj9o\n",
      "  Args:\n",
      "    query: 1706.03762\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, base\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":\"1706.03762\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".finalvenv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
